# Distributed Deep Learning

Led by Corey Adams and Huihuo Zheng from ALCF

This section of the workshop will introduce to you the methods we use to run distributed deep learning training on ALCF resources like Theta and ThetaGPU.

We show distributed training using two frameworks: 
1. [Horovod](Horovod/) (for [TensorFlow](tensorflow.org) and [PyTorch](pytorch.org)), and
2. [DistributedDataParallel](DDP/) (DDP) (for PyTorch only).
