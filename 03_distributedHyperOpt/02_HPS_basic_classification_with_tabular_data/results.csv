activation,batch_size,dropout_rate,learning_rate,num_epochs,units,id,objective,elapsed_sec,duration
relu,85,0.5227226893578312,0.00011766787907633265,21,89,1,0.6065573692321777,8.749297857284546,5.645847797393799
softplus,120,0.5561643738720652,2.0401343790562167e-05,99,56,2,0.8032786846160889,13.111065864562988,4.17230224609375
relu,27,0.545330850120652,1.2563365992171263e-05,41,66,3,0.5081967115402222,16.618206024169922,3.339708089828491
linear,219,0.46492665754274004,3.478774228126891e-05,74,24,4,0.4590163826942444,20.563667058944702,3.767930746078491
tanh,215,0.5527478316666308,1.7007226886083128e-05,39,15,5,0.5245901346206665,24.19187879562378,3.341249942779541
