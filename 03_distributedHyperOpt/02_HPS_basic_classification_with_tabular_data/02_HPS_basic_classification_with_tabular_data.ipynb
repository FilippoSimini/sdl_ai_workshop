{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f4dc356b",
   "metadata": {},
   "source": [
    "<img src=\"Figures/Deephyper.png\" style=\"height: 200px;\">\n",
    "\n",
    "<h1><center>Hyperparameter search for classification with Tabular data</center></h1>\n",
    "\n",
    "<div class=\"alert alert-info\">\n",
    "    \n",
    "<b>Reference</b>\n",
    "    \n",
    "This tutorial is based on materials from the Keras Documentation:\n",
    "* [Structured data classification from scratch](https://keras.io/examples/structured_data/structured_data_classification_from_scratch/)\n",
    "    \n",
    "</div>\n",
    "\n",
    "\n",
    "<div class=\"alert alert-warning\">\n",
    "\n",
    "<b>Warning</b>\n",
    "    \n",
    "By design asyncio does not allow nested event loops. Jupyter is using Tornado which already starts an event loop. Therefore the following patch is required to run this tutorial.\n",
    "    \n",
    "This tutorial should be run with `tensorFlow>=2.6`.\n",
    "    \n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bb4474f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: nest_asyncio in /Users/romainegele/opt/anaconda3/envs/dhtfp/lib/python3.8/site-packages (1.5.1)\r\n"
     ]
    }
   ],
   "source": [
    "!pip install nest_asyncio\n",
    "\n",
    "import nest_asyncio\n",
    "nest_asyncio.apply()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38664b59",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-info\">\n",
    "    \n",
    "<b>Note</b>\n",
    "    \n",
    "The following environment variables can be used to avoid the logging of **some** Tensorflow *DEBUG*, *INFO* and *WARNING* statements.\n",
    "    \n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "320e7d27",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "os.environ[\"TF_CPP_MIN_LOG_LEVEL\"] = str(3)\n",
    "os.environ[\"AUTOGRAPH_VERBOSITY\"] = str(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0360c86e",
   "metadata": {},
   "source": [
    "## Imports\n",
    "\n",
    "<div class=\"alert alert-block alert-danger\">\n",
    "    \n",
    "<b>Danger</b> \n",
    "\n",
    "The following cell contains Tensorflow import `import tensorflow as tf`. It is important to follow this strategy instead of `from tensorflow.keras.layers import ...` to avoid non-serializable data, creating crashed during the search. For example, the original Keras tutorial was using the following set of imports which was creating a serialization error in our use case.\n",
    "    \n",
    "```python\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "...\n",
    "from tensorflow.keras.layers import IntegerLookup\n",
    "from tensorflow.keras.layers import Normalization\n",
    "from tensorflow.keras.layers import StringLookup\n",
    "```\n",
    "    \n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f3a37b1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import ray\n",
    "import pandas as pd\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9061925",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-info\">\n",
    "    \n",
    "<b>Note</b>\n",
    "    \n",
    "The following can be used to detect if **GPU** devices are available on the current host. Therefore, this notebook will automatically adapt the parallel execution based on the ressources available locally. However, it will not be the case if many compute nodes are requested.\n",
    "    \n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "da5e0602",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No GPU available\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.python.client import device_lib\n",
    "\n",
    "def get_available_gpus():\n",
    "    local_device_protos = device_lib.list_local_devices()\n",
    "    return [x.name for x in local_device_protos if x.device_type == \"GPU\"]\n",
    "\n",
    "n_gpus = len(get_available_gpus())\n",
    "is_gpu_available = n_gpus > 0\n",
    "\n",
    "if is_gpu_available:\n",
    "    print(f\"{n_gpus} GPU{'s are' if n_gpus > 1 else ' is'} available.\")\n",
    "else:\n",
    "    print(\"No GPU available\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c702c644",
   "metadata": {},
   "source": [
    "### The dataset (from Keras.io)\n",
    "\n",
    "The [dataset](https://archive.ics.uci.edu/ml/datasets/heart+Disease) is provided by the\n",
    "Cleveland Clinic Foundation for Heart Disease.\n",
    "It's a CSV file with 303 rows. Each row contains information about a patient (a\n",
    "**sample**), and each column describes an attribute of the patient (a **feature**). We\n",
    "use the features to predict whether a patient has a heart disease (**binary\n",
    "classification**).\n",
    "\n",
    "Here's the description of each feature:\n",
    "\n",
    "Column| Description| Feature Type\n",
    "------------|--------------------|----------------------\n",
    "Age | Age in years | Numerical\n",
    "Sex | (1 = male; 0 = female) | Categorical\n",
    "CP | Chest pain type (0, 1, 2, 3, 4) | Categorical\n",
    "Trestbpd | Resting blood pressure (in mm Hg on admission) | Numerical\n",
    "Chol | Serum cholesterol in mg/dl | Numerical\n",
    "FBS | fasting blood sugar in 120 mg/dl (1 = true; 0 = false) | Categorical\n",
    "RestECG | Resting electrocardiogram results (0, 1, 2) | Categorical\n",
    "Thalach | Maximum heart rate achieved | Numerical\n",
    "Exang | Exercise induced angina (1 = yes; 0 = no) | Categorical\n",
    "Oldpeak | ST depression induced by exercise relative to rest | Numerical\n",
    "Slope | Slope of the peak exercise ST segment | Numerical\n",
    "CA | Number of major vessels (0-3) colored by fluoroscopy | Both numerical & categorical\n",
    "Thal | 3 = normal; 6 = fixed defect; 7 = reversible defect | Categorical\n",
    "Target | Diagnosis of heart disease (1 = true; 0 = false) | Target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9499cd94",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data():\n",
    "#     file_url = \"http://storage.googleapis.com/download.tensorflow.org/data/heart.csv\"\n",
    "    file_url = \"heart.csv\"\n",
    "    dataframe = pd.read_csv(file_url)\n",
    "\n",
    "    val_dataframe = dataframe.sample(frac=0.2, random_state=1337)\n",
    "    train_dataframe = dataframe.drop(val_dataframe.index)\n",
    "\n",
    "    return train_dataframe, val_dataframe\n",
    "\n",
    "\n",
    "def dataframe_to_dataset(dataframe):\n",
    "    dataframe = dataframe.copy()\n",
    "    labels = dataframe.pop(\"target\")\n",
    "    ds = tf.data.Dataset.from_tensor_slices((dict(dataframe), labels))\n",
    "    ds = ds.shuffle(buffer_size=len(dataframe))\n",
    "    return ds"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ceb5938",
   "metadata": {},
   "source": [
    "## Preprocessing & encoding of features\n",
    "\n",
    "The next cells use `tf.keras.layers.Normalization()` to apply standard scaling on the features. Then, the `tf.keras.layers.StringLookup` and `tf.keras.layers.IntegerLookup` are used to encode categorical variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "996814d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def encode_numerical_feature(feature, name, dataset):\n",
    "    # Create a Normalization layer for our feature\n",
    "    normalizer = tf.keras.layers.Normalization()\n",
    "\n",
    "    # Prepare a Dataset that only yields our feature\n",
    "    feature_ds = dataset.map(lambda x, y: x[name])\n",
    "    feature_ds = feature_ds.map(lambda x: tf.expand_dims(x, -1))\n",
    "\n",
    "    # Learn the statistics of the data\n",
    "    normalizer.adapt(feature_ds)\n",
    "\n",
    "    # Normalize the input feature\n",
    "    encoded_feature = normalizer(feature)\n",
    "    return encoded_feature\n",
    "\n",
    "\n",
    "def encode_categorical_feature(feature, name, dataset, is_string):\n",
    "    lookup_class = (\n",
    "        tf.keras.layers.StringLookup if is_string else tf.keras.layers.IntegerLookup\n",
    "    )\n",
    "    # Create a lookup layer which will turn strings into integer indices\n",
    "    lookup = lookup_class(output_mode=\"binary\")\n",
    "\n",
    "    # Prepare a Dataset that only yields our feature\n",
    "    feature_ds = dataset.map(lambda x, y: x[name])\n",
    "    feature_ds = feature_ds.map(lambda x: tf.expand_dims(x, -1))\n",
    "\n",
    "    # Learn the set of possible string values and assign them a fixed integer index\n",
    "    lookup.adapt(feature_ds)\n",
    "\n",
    "    # Turn the string input into integer indices\n",
    "    encoded_feature = lookup(feature)\n",
    "    return encoded_feature"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8743319",
   "metadata": {},
   "source": [
    "## Define the run-function\n",
    "\n",
    "The run-function defines how the objective that we want to maximize is computed. It takes a `config` dictionnary as input and often returns a scalar value that we want to maximize. The `config` contains a sample value of hyperparameters to we want to tune. In this example we will search for:\n",
    "* `units` (default value: `32`)\n",
    "* `activation` (default value: `\"relu\"`)\n",
    "* `dropout_rate` (default value: `0.5`)\n",
    "* `num_epochs` (default value: `50`)\n",
    "* `batch_size` (default value: `32`)\n",
    "* `learning_rate` (default value: `1e-3`)\n",
    "An hyperparameter value can be acessed easily in the dictionnary through the corresponding key, for example `config[\"units\"]`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2f99f031",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run(config: dict):\n",
    "    tf.autograph.set_verbosity(0)\n",
    "    \n",
    "    train_dataframe, val_dataframe = load_data()\n",
    "\n",
    "    train_ds = dataframe_to_dataset(train_dataframe)\n",
    "    val_ds = dataframe_to_dataset(val_dataframe)\n",
    "\n",
    "    train_ds = train_ds.batch(config[\"batch_size\"])\n",
    "    val_ds = val_ds.batch(config[\"batch_size\"])\n",
    "\n",
    "    # Categorical features encoded as integers\n",
    "    sex = tf.keras.Input(shape=(1,), name=\"sex\", dtype=\"int64\")\n",
    "    cp = tf.keras.Input(shape=(1,), name=\"cp\", dtype=\"int64\")\n",
    "    fbs = tf.keras.Input(shape=(1,), name=\"fbs\", dtype=\"int64\")\n",
    "    restecg = tf.keras.Input(shape=(1,), name=\"restecg\", dtype=\"int64\")\n",
    "    exang = tf.keras.Input(shape=(1,), name=\"exang\", dtype=\"int64\")\n",
    "    ca = tf.keras.Input(shape=(1,), name=\"ca\", dtype=\"int64\")\n",
    "\n",
    "    # Categorical feature encoded as string\n",
    "    thal = tf.keras.Input(shape=(1,), name=\"thal\", dtype=\"string\")\n",
    "\n",
    "    # Numerical features\n",
    "    age = tf.keras.Input(shape=(1,), name=\"age\")\n",
    "    trestbps = tf.keras.Input(shape=(1,), name=\"trestbps\")\n",
    "    chol = tf.keras.Input(shape=(1,), name=\"chol\")\n",
    "    thalach = tf.keras.Input(shape=(1,), name=\"thalach\")\n",
    "    oldpeak = tf.keras.Input(shape=(1,), name=\"oldpeak\")\n",
    "    slope = tf.keras.Input(shape=(1,), name=\"slope\")\n",
    "\n",
    "    all_inputs = [\n",
    "        sex,\n",
    "        cp,\n",
    "        fbs,\n",
    "        restecg,\n",
    "        exang,\n",
    "        ca,\n",
    "        thal,\n",
    "        age,\n",
    "        trestbps,\n",
    "        chol,\n",
    "        thalach,\n",
    "        oldpeak,\n",
    "        slope,\n",
    "    ]\n",
    "\n",
    "    # Integer categorical features\n",
    "    sex_encoded = encode_categorical_feature(sex, \"sex\", train_ds, False)\n",
    "    cp_encoded = encode_categorical_feature(cp, \"cp\", train_ds, False)\n",
    "    fbs_encoded = encode_categorical_feature(fbs, \"fbs\", train_ds, False)\n",
    "    restecg_encoded = encode_categorical_feature(restecg, \"restecg\", train_ds, False)\n",
    "    exang_encoded = encode_categorical_feature(exang, \"exang\", train_ds, False)\n",
    "    ca_encoded = encode_categorical_feature(ca, \"ca\", train_ds, False)\n",
    "\n",
    "    # String categorical features\n",
    "    thal_encoded = encode_categorical_feature(thal, \"thal\", train_ds, True)\n",
    "\n",
    "    # Numerical features\n",
    "    age_encoded = encode_numerical_feature(age, \"age\", train_ds)\n",
    "    trestbps_encoded = encode_numerical_feature(trestbps, \"trestbps\", train_ds)\n",
    "    chol_encoded = encode_numerical_feature(chol, \"chol\", train_ds)\n",
    "    thalach_encoded = encode_numerical_feature(thalach, \"thalach\", train_ds)\n",
    "    oldpeak_encoded = encode_numerical_feature(oldpeak, \"oldpeak\", train_ds)\n",
    "    slope_encoded = encode_numerical_feature(slope, \"slope\", train_ds)\n",
    "\n",
    "    all_features = tf.keras.layers.concatenate(\n",
    "        [\n",
    "            sex_encoded,\n",
    "            cp_encoded,\n",
    "            fbs_encoded,\n",
    "            restecg_encoded,\n",
    "            exang_encoded,\n",
    "            slope_encoded,\n",
    "            ca_encoded,\n",
    "            thal_encoded,\n",
    "            age_encoded,\n",
    "            trestbps_encoded,\n",
    "            chol_encoded,\n",
    "            thalach_encoded,\n",
    "            oldpeak_encoded,\n",
    "        ]\n",
    "    )\n",
    "    x = tf.keras.layers.Dense(config[\"units\"], activation=config[\"activation\"])(\n",
    "        all_features\n",
    "    )\n",
    "    x = tf.keras.layers.Dropout(config[\"dropout_rate\"])(x)\n",
    "    output = tf.keras.layers.Dense(1, activation=\"sigmoid\")(x)\n",
    "    model = tf.keras.Model(all_inputs, output)\n",
    "\n",
    "    optimizer = tf.keras.optimizers.Adam(learning_rate=config[\"learning_rate\"])\n",
    "    model.compile(optimizer, \"binary_crossentropy\", metrics=[\"accuracy\"])\n",
    "\n",
    "    history = model.fit(\n",
    "        train_ds, epochs=config[\"num_epochs\"], validation_data=val_ds, verbose=0\n",
    "    )\n",
    "\n",
    "    return history.history[\"val_accuracy\"][-1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea800ab1",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-success\">\n",
    "    \n",
    "<b>Important</b>\n",
    "    \n",
    "The objective maximised by DeepHyper is the scalar value returned by the `run`-function. In this tutorial it corresponds to the validation accuracy of the last epoch of training which we retrieve in the `History` object returned by the `model.fit(...)` call.\n",
    "    \n",
    "```python\n",
    "...\n",
    "history = model.fit(\n",
    "    train_ds, epochs=config[\"num_epochs\"], validation_data=val_ds, verbose=0\n",
    ")\n",
    "\n",
    "return history.history[\"val_accuracy\"][-1]\n",
    "...\n",
    "```\n",
    "\n",
    "Using an objective like `max(history.history[\"val_accuracy\"])` can have undesired effect such as training curves passing by a local maximum and then dropping which will not generate a model in capacity of ingesting well more data in the future.\n",
    "    \n",
    "</div>\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f1719e4",
   "metadata": {},
   "source": [
    "## Evaluate a default configuration\n",
    "\n",
    "We evaluate the performance of the default set of hyperparameters provided in the Keras tutorial."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5ab7ab0c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-09-27 18:00:57,707\tINFO services.py:1267 -- View the Ray dashboard at \u001b[1m\u001b[32mhttp://127.0.0.1:8265\u001b[39m\u001b[22m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy Default Configuration:  0.820\n"
     ]
    }
   ],
   "source": [
    "# We define a dictionnary for the default values\n",
    "default_config = {\n",
    "    \"units\": 32,\n",
    "    \"activation\": \"relu\",\n",
    "    \"dropout_rate\": 0.5,\n",
    "    \"num_epochs\": 50,\n",
    "    \"batch_size\": 32,\n",
    "    \"learning_rate\": 1e-3,\n",
    "}\n",
    "\n",
    "# We launch the Ray run-time depending of the detected local ressources\n",
    "# and execute the `run` function with the default configuration\n",
    "# WARNING: in the case of GPUs it is important to follow this scheme\n",
    "# to avoid multiple processes (Ray workers vs current process) to lock\n",
    "# the same GPU.\n",
    "if is_gpu_available:\n",
    "    \n",
    "    if not(ray.is_initialized()):\n",
    "        ray.init(num_cpus=n_gpus, num_gpus=n_gpus, log_to_driver=False)\n",
    "    \n",
    "    run_default = ray.remote(num_cpus=1, num_gpus=1)(run)\n",
    "    \n",
    "    objective_default = ray.get(run_default.remote(default_config))\n",
    "    \n",
    "else:\n",
    "    \n",
    "    if not(ray.is_initialized()):\n",
    "        ray.init(num_cpus=1, log_to_driver=False)\n",
    "    \n",
    "    run_default = run\n",
    "    \n",
    "    objective_default = run_default(default_config)\n",
    "    \n",
    "print(f\"Accuracy Default Configuration:  {objective_default:.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ca589b5",
   "metadata": {},
   "source": [
    "## Define the Hyperparameter optimization problem\n",
    "\n",
    "Hyperparameter ranges are defined using the following syntax:\n",
    "\n",
    "* Discrete integer ranges are generated from a tuple `(lower: int, upper: int)`\n",
    "* Continuous prarameters are generated from a tuple `(lower: float, upper: float)`\n",
    "* Categorical or nonordinal hyperparameter ranges can be given as a list of possible values `[val1, val2, ...]`\n",
    "\n",
    "We provide the default configuration of hyperparameters as a starting point of the problem."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5813bb59",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Configuration space object:\n",
       "  Hyperparameters:\n",
       "    activation, Type: Categorical, Choices: {elu, gelu, hard_sigmoid, linear, relu, selu, sigmoid, softplus, softsign, swish, tanh}, Default: elu\n",
       "    batch_size, Type: UniformInteger, Range: [8, 256], Default: 45, on log-scale\n",
       "    dropout_rate, Type: UniformFloat, Range: [0.0, 0.6], Default: 0.3\n",
       "    learning_rate, Type: UniformFloat, Range: [1e-05, 0.01], Default: 0.0003162278, on log-scale\n",
       "    num_epochs, Type: UniformInteger, Range: [10, 100], Default: 55\n",
       "    units, Type: UniformInteger, Range: [8, 128], Default: 68\n",
       "\n",
       "\n",
       "  Starting Point:\n",
       "{0: {'activation': 'relu',\n",
       "     'batch_size': 32,\n",
       "     'dropout_rate': 0.5,\n",
       "     'learning_rate': 0.001,\n",
       "     'num_epochs': 50,\n",
       "     'units': 32}}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from deephyper.problem import HpProblem\n",
    "\n",
    "\n",
    "problem = HpProblem()\n",
    "\n",
    "# Discrete hyperparameter (sampled with uniform prior)\n",
    "problem.add_hyperparameter((8, 128), \"units\")\n",
    "\n",
    "# Categorical hyperparameter (sampled with uniform prior)\n",
    "ACTIVATIONS = [\"elu\", \"gelu\", \"hard_sigmoid\", \"linear\", \"relu\", \"selu\",\n",
    "    \"sigmoid\", \"softplus\", \"softsign\", \"swish\", \"tanh\",\n",
    "]\n",
    "problem.add_hyperparameter(ACTIVATIONS, \"activation\")\n",
    "\n",
    "# Real hyperparameter (sampled with uniform prior)\n",
    "problem.add_hyperparameter((0.0, 0.6), \"dropout_rate\")\n",
    "\n",
    "problem.add_hyperparameter((10, 100), \"num_epochs\")\n",
    "\n",
    "# Discrete and Real hyperparameters (sampled with log-uniform)\n",
    "problem.add_hyperparameter((8, 256, \"log-uniform\"), \"batch_size\")\n",
    "problem.add_hyperparameter((1e-5, 1e-2, \"log-uniform\"), \"learning_rate\")\n",
    "\n",
    "# Add a starting point to try first\n",
    "problem.add_starting_point(**default_config)\n",
    "\n",
    "problem"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "596900f9",
   "metadata": {},
   "source": [
    "## Define the evaluator object\n",
    "\n",
    "The `Evaluator` object allows to change the parallelization backend used by DeepHyper. It is a standalone object which schedule the execution of remote tasks. All evaluators needs a `run_function` to be instantiated. Then a keyword `method` defines the backend (e.g., `\"ray\"`) and the `method_kwargs` corresponds to keyword arguments of this chosen `method`.\n",
    "\n",
    "```python\n",
    "evaluator = Evaluator.create(run_function, method, method_kwargs)\n",
    "```\n",
    "\n",
    "Once created the `evaluator.num_workers` gives access to the number of available parallel workers.\n",
    "\n",
    "Finally, to submit and collect tasks to the evaluator one just needs to use the following interface:\n",
    "\n",
    "```python\n",
    "configs = [...]\n",
    "evaluator.submit(configs)\n",
    "...\n",
    "tasks_done = evaluator.get(\"BATCH\", size=1) # For asynchronous\n",
    "tasks_done = evaluator.get(\"ALL\") # For batch synchronous\n",
    "```\n",
    "\n",
    "<div class=\"alert alert-warning\">\n",
    "\n",
    "<b>Warning</b>\n",
    "\n",
    "Each `Evaluator` saves its own state, therefore it is crutial to create a new evaluator when launching a fresh search.\n",
    "    \n",
    "</div>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b3f0be13",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created new evaluator with 1 worker and config: {'num_cpus': 1, 'num_cpus_per_task': 1, 'callbacks': [<deephyper.evaluator.callback.LoggerCallback object at 0x7f875b2355e0>]}\n"
     ]
    }
   ],
   "source": [
    "from deephyper.evaluator.evaluate import Evaluator\n",
    "from deephyper.evaluator.callback import LoggerCallback\n",
    "\n",
    "\n",
    "def get_evaluator(run_function):\n",
    "    \n",
    "    # Default arguments for Ray: 1 worker and 1 worker per evaluation\n",
    "    method_kwargs = {\n",
    "        \"num_cpus\": 1, \n",
    "        \"num_cpus_per_task\": 1,\n",
    "        \"callbacks\": [LoggerCallback()]\n",
    "    }\n",
    "\n",
    "    # If GPU devices are detected then it will create 'n_gpus' workers\n",
    "    # and use 1 worker for each evaluation\n",
    "    if is_gpu_available:\n",
    "        method_kwargs[\"num_cpus\"] = n_gpus\n",
    "        method_kwargs[\"num_gpus\"] = n_gpus\n",
    "        method_kwargs[\"num_cpus_per_task\"] = 1\n",
    "        method_kwargs[\"num_gpus_per_task\"] = 1\n",
    "\n",
    "    evaluator = Evaluator.create(\n",
    "        run_function, \n",
    "        method=\"ray\", \n",
    "        method_kwargs=method_kwargs\n",
    "    )\n",
    "    print(f\"Created new evaluator with {evaluator.num_workers} worker{'s' if evaluator.num_workers > 1 else ''} and config: {method_kwargs}\", )\n",
    "    \n",
    "    return evaluator\n",
    "\n",
    "evaluator_1 = get_evaluator(run)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "392998bc",
   "metadata": {},
   "source": [
    "## Define and run the asynchronous model-based search\n",
    "\n",
    "A primary pillar of hyperparameter search in DeepHyper is given by an asynchronous parallel model-based search paradigm (henceforth AMBS). AMBS may be described in the following algorithm:\n",
    "\n",
    "<img src=\"Figures/AMBS.png\" style=\"width: 500px;\">\n",
    "\n",
    "Following the parallelized evaluation of these configurations, a low-fidelity and high efficiency model (henceforth \"the surrogate\") is devised to reproduce the relationship between the input variables involved in the model (i.e., the choice of hyperparameters) and the outputs (which are generally a measure of validation data accuracy). After obtaining this surrogate of the validation accuracy, we may utilize ideas from classical methods in Bayesian optimization literature for adaptively sample the search space of hyperparameters.\n",
    "\n",
    "First, the surrogate is used to obtain an estimate for the mean value of the validation accuracy at a certain sampling location $x$ in addition to an estimated variance. The latter requirement restricts us to the use of high efficiency data-driven modeling strategies that have inbuilt variance estimates (such as a Gaussian process or Random Forest regressor). Regions where the mean is high represent opportunities for exploitation and regions where the variance is high represent opportunities for exploration. An optimistic acquisition function called UCB can be constructed using these two quantities:\n",
    "\n",
    "$$L_{\\text{UCB}}(x) = \\mu(x) + \\kappa \\cdot \\sigma(x)$$\n",
    "\n",
    "The *unevaluated* hyperparameter configurations that *maximize* the acquisition function are chosen for the next batch of evaluations. Note that the choice of the variance weighting parameter $\\kappa$ controls the degree of exploration in the hyperparameter search with zero indicating purely exploitation (unseen configurations where the predicted accuracy is highest will be sampled). The top `s` configurations are selected for the new batch. The following schematic demonstrates this process:\n",
    "\n",
    "<img src=\"Figures/BO_AF.png\" width=\"500\">\n",
    "\n",
    "The process of obtaining `s` configurations relies on the \"constant-liar\" strategy where a sampled configuration is mapped to a dummy output given by a bulk metric of all the evaluated configurations thus far (such as the maximum, mean or median validation accuracy). Prior to sampling the next configuration by acquisition function maximization, the surrogate is retrained with the dummy output as a data point. As the true validation accuracy becomes available for one of the sampled configurations, the dummy output is replaced and the surrogate is updated. This allows for scalable asynchronous (or batch synchronous) sampling of new hyperparameter configurations. \n",
    "\n",
    "####  Choice of surrogate model\n",
    "\n",
    "Users should note that our choice of the surrogate is given by the Random Forest regressor due to its ability to handle non-ordinal data (hyperparameter configurations may not be purely continuous or even numerical). Evidence for how they outperform other methods (such as Gaussian processes) is also available in [1]\n",
    "\n",
    "<img src=\"Figures/RFR.png\" width=\"400\">\n",
    "\n",
    "<img src=\"Figures/RFR_Superior.png\" width=\"800\">\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "09dc7abd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from deephyper.search.hps import AMBS\n",
    "\n",
    "# Uncomment the following line to show the arguments of AMBS.\n",
    "# AMBS?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1e00f0f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instanciate the search with the problem and a specific evaluator\n",
    "search = AMBS(problem, evaluator_1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5fad52a5",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-info\">\n",
    "    \n",
    "<b>Note</b>\n",
    "    \n",
    "All DeepHyper's search algorithm have two stopping criteria:\n",
    "\n",
    "* `max_evals`: (*int*) which defines the maximum number of evaluations that we want to perform. Default to `-1` for an infinite number.\n",
    "* `timeout`: (positive *int*) which defines a time budget (in secondes) before stopping the search. Default to `None` for an infinite time budget.\n",
    "    \n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "457546ce",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[00001] -- best objective: 0.8196721076965332 -- received objective: 0.8196721076965332\n",
      "[00002] -- best objective: 0.8196721076965332 -- received objective: 0.8196721076965332\n",
      "[00003] -- best objective: 0.8196721076965332 -- received objective: 0.8196721076965332\n",
      "[00004] -- best objective: 0.8196721076965332 -- received objective: 0.7868852615356445\n",
      "[00005] -- best objective: 0.8196721076965332 -- received objective: 0.7868852615356445\n",
      "[00006] -- best objective: 0.8524590134620667 -- received objective: 0.8524590134620667\n",
      "[00007] -- best objective: 0.8524590134620667 -- received objective: 0.8360655903816223\n",
      "[00008] -- best objective: 0.8524590134620667 -- received objective: 0.7704917788505554\n",
      "[00009] -- best objective: 0.8524590134620667 -- received objective: 0.8032786846160889\n",
      "[00010] -- best objective: 0.8524590134620667 -- received objective: 0.24590164422988892\n"
     ]
    }
   ],
   "source": [
    "results = search.search(max_evals=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c54414b",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-warning\">\n",
    "\n",
    "<b>Warning</b>\n",
    "    \n",
    "The `search` call does not output any information about the current status of the search. However, `results.csv` file is created in the local directly and can be visualized to see finished tasks.\n",
    "    \n",
    "</div>\n",
    "\n",
    "The returned `results` is a Pandas Dataframe where columns are hyperparameters and information stored by the evaluator:\n",
    "\n",
    "* `id` is a unique identifier corresponding to the order of creation of tasks\n",
    "* `objective` is the value returned by the run-function\n",
    "* `elapsed_sec` is the time (in secondes) when the task completed since the creation of the evaluator.\n",
    "* `duration` is the duration (in secondes) of the task to be computed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "87bc93b8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>activation</th>\n",
       "      <th>batch_size</th>\n",
       "      <th>dropout_rate</th>\n",
       "      <th>learning_rate</th>\n",
       "      <th>num_epochs</th>\n",
       "      <th>units</th>\n",
       "      <th>id</th>\n",
       "      <th>objective</th>\n",
       "      <th>elapsed_sec</th>\n",
       "      <th>duration</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>relu</td>\n",
       "      <td>32</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.001000</td>\n",
       "      <td>50</td>\n",
       "      <td>32</td>\n",
       "      <td>1</td>\n",
       "      <td>0.819672</td>\n",
       "      <td>6.230122</td>\n",
       "      <td>6.206514</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>hard_sigmoid</td>\n",
       "      <td>42</td>\n",
       "      <td>0.540868</td>\n",
       "      <td>0.000824</td>\n",
       "      <td>51</td>\n",
       "      <td>70</td>\n",
       "      <td>2</td>\n",
       "      <td>0.819672</td>\n",
       "      <td>10.061022</td>\n",
       "      <td>3.629809</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>hard_sigmoid</td>\n",
       "      <td>11</td>\n",
       "      <td>0.022177</td>\n",
       "      <td>0.000412</td>\n",
       "      <td>60</td>\n",
       "      <td>124</td>\n",
       "      <td>3</td>\n",
       "      <td>0.819672</td>\n",
       "      <td>15.157963</td>\n",
       "      <td>4.885490</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>tanh</td>\n",
       "      <td>9</td>\n",
       "      <td>0.423570</td>\n",
       "      <td>0.000035</td>\n",
       "      <td>44</td>\n",
       "      <td>122</td>\n",
       "      <td>4</td>\n",
       "      <td>0.786885</td>\n",
       "      <td>19.546616</td>\n",
       "      <td>4.212101</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>softplus</td>\n",
       "      <td>36</td>\n",
       "      <td>0.536837</td>\n",
       "      <td>0.000119</td>\n",
       "      <td>94</td>\n",
       "      <td>65</td>\n",
       "      <td>5</td>\n",
       "      <td>0.786885</td>\n",
       "      <td>24.468021</td>\n",
       "      <td>4.746074</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>softplus</td>\n",
       "      <td>10</td>\n",
       "      <td>0.265353</td>\n",
       "      <td>0.000790</td>\n",
       "      <td>19</td>\n",
       "      <td>21</td>\n",
       "      <td>6</td>\n",
       "      <td>0.852459</td>\n",
       "      <td>27.508826</td>\n",
       "      <td>2.867473</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>tanh</td>\n",
       "      <td>9</td>\n",
       "      <td>0.349124</td>\n",
       "      <td>0.000289</td>\n",
       "      <td>18</td>\n",
       "      <td>14</td>\n",
       "      <td>7</td>\n",
       "      <td>0.836066</td>\n",
       "      <td>30.627359</td>\n",
       "      <td>2.923309</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>relu</td>\n",
       "      <td>243</td>\n",
       "      <td>0.090046</td>\n",
       "      <td>0.000832</td>\n",
       "      <td>93</td>\n",
       "      <td>13</td>\n",
       "      <td>8</td>\n",
       "      <td>0.770492</td>\n",
       "      <td>35.201301</td>\n",
       "      <td>4.289235</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>elu</td>\n",
       "      <td>254</td>\n",
       "      <td>0.220927</td>\n",
       "      <td>0.006949</td>\n",
       "      <td>27</td>\n",
       "      <td>11</td>\n",
       "      <td>9</td>\n",
       "      <td>0.803279</td>\n",
       "      <td>39.339825</td>\n",
       "      <td>3.830671</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>relu</td>\n",
       "      <td>8</td>\n",
       "      <td>0.463332</td>\n",
       "      <td>0.000019</td>\n",
       "      <td>11</td>\n",
       "      <td>45</td>\n",
       "      <td>10</td>\n",
       "      <td>0.245902</td>\n",
       "      <td>42.353928</td>\n",
       "      <td>2.770527</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     activation  batch_size  dropout_rate  learning_rate  num_epochs  units  \\\n",
       "0          relu          32      0.500000       0.001000          50     32   \n",
       "1  hard_sigmoid          42      0.540868       0.000824          51     70   \n",
       "2  hard_sigmoid          11      0.022177       0.000412          60    124   \n",
       "3          tanh           9      0.423570       0.000035          44    122   \n",
       "4      softplus          36      0.536837       0.000119          94     65   \n",
       "5      softplus          10      0.265353       0.000790          19     21   \n",
       "6          tanh           9      0.349124       0.000289          18     14   \n",
       "7          relu         243      0.090046       0.000832          93     13   \n",
       "8           elu         254      0.220927       0.006949          27     11   \n",
       "9          relu           8      0.463332       0.000019          11     45   \n",
       "\n",
       "   id  objective  elapsed_sec  duration  \n",
       "0   1   0.819672     6.230122  6.206514  \n",
       "1   2   0.819672    10.061022  3.629809  \n",
       "2   3   0.819672    15.157963  4.885490  \n",
       "3   4   0.786885    19.546616  4.212101  \n",
       "4   5   0.786885    24.468021  4.746074  \n",
       "5   6   0.852459    27.508826  2.867473  \n",
       "6   7   0.836066    30.627359  2.923309  \n",
       "7   8   0.770492    35.201301  4.289235  \n",
       "8   9   0.803279    39.339825  3.830671  \n",
       "9  10   0.245902    42.353928  2.770527  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbd8b3e4",
   "metadata": {},
   "source": [
    "The search can be continued without any issue."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f2e6af67",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[00011] -- best objective: 0.8524590134620667 -- received objective: 0.7704917788505554\n",
      "[00012] -- best objective: 0.8524590134620667 -- received objective: 0.8032786846160889\n",
      "[00013] -- best objective: 0.8524590134620667 -- received objective: 0.7704917788505554\n",
      "[00014] -- best objective: 0.8524590134620667 -- received objective: 0.6557376980781555\n",
      "[00015] -- best objective: 0.8524590134620667 -- received objective: 0.8032786846160889\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>activation</th>\n",
       "      <th>batch_size</th>\n",
       "      <th>dropout_rate</th>\n",
       "      <th>learning_rate</th>\n",
       "      <th>num_epochs</th>\n",
       "      <th>units</th>\n",
       "      <th>id</th>\n",
       "      <th>objective</th>\n",
       "      <th>elapsed_sec</th>\n",
       "      <th>duration</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>relu</td>\n",
       "      <td>32</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.001000</td>\n",
       "      <td>50</td>\n",
       "      <td>32</td>\n",
       "      <td>1</td>\n",
       "      <td>0.819672</td>\n",
       "      <td>6.230122</td>\n",
       "      <td>6.206514</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>hard_sigmoid</td>\n",
       "      <td>42</td>\n",
       "      <td>0.540868</td>\n",
       "      <td>0.000824</td>\n",
       "      <td>51</td>\n",
       "      <td>70</td>\n",
       "      <td>2</td>\n",
       "      <td>0.819672</td>\n",
       "      <td>10.061022</td>\n",
       "      <td>3.629809</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>hard_sigmoid</td>\n",
       "      <td>11</td>\n",
       "      <td>0.022177</td>\n",
       "      <td>0.000412</td>\n",
       "      <td>60</td>\n",
       "      <td>124</td>\n",
       "      <td>3</td>\n",
       "      <td>0.819672</td>\n",
       "      <td>15.157963</td>\n",
       "      <td>4.885490</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>tanh</td>\n",
       "      <td>9</td>\n",
       "      <td>0.423570</td>\n",
       "      <td>0.000035</td>\n",
       "      <td>44</td>\n",
       "      <td>122</td>\n",
       "      <td>4</td>\n",
       "      <td>0.786885</td>\n",
       "      <td>19.546616</td>\n",
       "      <td>4.212101</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>softplus</td>\n",
       "      <td>36</td>\n",
       "      <td>0.536837</td>\n",
       "      <td>0.000119</td>\n",
       "      <td>94</td>\n",
       "      <td>65</td>\n",
       "      <td>5</td>\n",
       "      <td>0.786885</td>\n",
       "      <td>24.468021</td>\n",
       "      <td>4.746074</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>softplus</td>\n",
       "      <td>10</td>\n",
       "      <td>0.265353</td>\n",
       "      <td>0.000790</td>\n",
       "      <td>19</td>\n",
       "      <td>21</td>\n",
       "      <td>6</td>\n",
       "      <td>0.852459</td>\n",
       "      <td>27.508826</td>\n",
       "      <td>2.867473</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>tanh</td>\n",
       "      <td>9</td>\n",
       "      <td>0.349124</td>\n",
       "      <td>0.000289</td>\n",
       "      <td>18</td>\n",
       "      <td>14</td>\n",
       "      <td>7</td>\n",
       "      <td>0.836066</td>\n",
       "      <td>30.627359</td>\n",
       "      <td>2.923309</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>relu</td>\n",
       "      <td>243</td>\n",
       "      <td>0.090046</td>\n",
       "      <td>0.000832</td>\n",
       "      <td>93</td>\n",
       "      <td>13</td>\n",
       "      <td>8</td>\n",
       "      <td>0.770492</td>\n",
       "      <td>35.201301</td>\n",
       "      <td>4.289235</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>elu</td>\n",
       "      <td>254</td>\n",
       "      <td>0.220927</td>\n",
       "      <td>0.006949</td>\n",
       "      <td>27</td>\n",
       "      <td>11</td>\n",
       "      <td>9</td>\n",
       "      <td>0.803279</td>\n",
       "      <td>39.339825</td>\n",
       "      <td>3.830671</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>relu</td>\n",
       "      <td>8</td>\n",
       "      <td>0.463332</td>\n",
       "      <td>0.000019</td>\n",
       "      <td>11</td>\n",
       "      <td>45</td>\n",
       "      <td>10</td>\n",
       "      <td>0.245902</td>\n",
       "      <td>42.353928</td>\n",
       "      <td>2.770527</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>hard_sigmoid</td>\n",
       "      <td>8</td>\n",
       "      <td>0.508307</td>\n",
       "      <td>0.000663</td>\n",
       "      <td>18</td>\n",
       "      <td>31</td>\n",
       "      <td>11</td>\n",
       "      <td>0.770492</td>\n",
       "      <td>45.383543</td>\n",
       "      <td>2.853912</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>relu</td>\n",
       "      <td>32</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.001000</td>\n",
       "      <td>50</td>\n",
       "      <td>32</td>\n",
       "      <td>12</td>\n",
       "      <td>0.803279</td>\n",
       "      <td>48.801837</td>\n",
       "      <td>6.254438</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>sigmoid</td>\n",
       "      <td>39</td>\n",
       "      <td>0.276085</td>\n",
       "      <td>0.001239</td>\n",
       "      <td>12</td>\n",
       "      <td>47</td>\n",
       "      <td>13</td>\n",
       "      <td>0.770492</td>\n",
       "      <td>51.559498</td>\n",
       "      <td>5.996970</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>relu</td>\n",
       "      <td>10</td>\n",
       "      <td>0.297972</td>\n",
       "      <td>0.000015</td>\n",
       "      <td>14</td>\n",
       "      <td>73</td>\n",
       "      <td>14</td>\n",
       "      <td>0.655738</td>\n",
       "      <td>54.878121</td>\n",
       "      <td>5.899749</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>softplus</td>\n",
       "      <td>14</td>\n",
       "      <td>0.051171</td>\n",
       "      <td>0.000017</td>\n",
       "      <td>74</td>\n",
       "      <td>35</td>\n",
       "      <td>15</td>\n",
       "      <td>0.803279</td>\n",
       "      <td>59.537077</td>\n",
       "      <td>7.691309</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      activation  batch_size  dropout_rate  learning_rate  num_epochs  units  \\\n",
       "0           relu          32      0.500000       0.001000          50     32   \n",
       "1   hard_sigmoid          42      0.540868       0.000824          51     70   \n",
       "2   hard_sigmoid          11      0.022177       0.000412          60    124   \n",
       "3           tanh           9      0.423570       0.000035          44    122   \n",
       "4       softplus          36      0.536837       0.000119          94     65   \n",
       "5       softplus          10      0.265353       0.000790          19     21   \n",
       "6           tanh           9      0.349124       0.000289          18     14   \n",
       "7           relu         243      0.090046       0.000832          93     13   \n",
       "8            elu         254      0.220927       0.006949          27     11   \n",
       "9           relu           8      0.463332       0.000019          11     45   \n",
       "10  hard_sigmoid           8      0.508307       0.000663          18     31   \n",
       "11          relu          32      0.500000       0.001000          50     32   \n",
       "12       sigmoid          39      0.276085       0.001239          12     47   \n",
       "13          relu          10      0.297972       0.000015          14     73   \n",
       "14      softplus          14      0.051171       0.000017          74     35   \n",
       "\n",
       "    id  objective  elapsed_sec  duration  \n",
       "0    1   0.819672     6.230122  6.206514  \n",
       "1    2   0.819672    10.061022  3.629809  \n",
       "2    3   0.819672    15.157963  4.885490  \n",
       "3    4   0.786885    19.546616  4.212101  \n",
       "4    5   0.786885    24.468021  4.746074  \n",
       "5    6   0.852459    27.508826  2.867473  \n",
       "6    7   0.836066    30.627359  2.923309  \n",
       "7    8   0.770492    35.201301  4.289235  \n",
       "8    9   0.803279    39.339825  3.830671  \n",
       "9   10   0.245902    42.353928  2.770527  \n",
       "10  11   0.770492    45.383543  2.853912  \n",
       "11  12   0.803279    48.801837  6.254438  \n",
       "12  13   0.770492    51.559498  5.996970  \n",
       "13  14   0.655738    54.878121  5.899749  \n",
       "14  15   0.803279    59.537077  7.691309  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results = search.search(max_evals=5)\n",
    "\n",
    "results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53d673da",
   "metadata": {},
   "source": [
    "Now that the search is over, let us print the best configuration found during this run."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f906a04f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The default configuration has an accuracy of 0.820. The best configuration found by DeepHyper has an accuracy 0.852, trained in 2.87 secondes and finished after 27.51 secondes of search.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'activation': 'softplus',\n",
       " 'batch_size': 10,\n",
       " 'dropout_rate': 0.2653530711115132,\n",
       " 'learning_rate': 0.0007904971222891,\n",
       " 'num_epochs': 19,\n",
       " 'units': 21,\n",
       " 'id': 6}"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "i_max = results.objective.argmax()\n",
    "best_config = results.iloc[i_max][:-3].to_dict()\n",
    "\n",
    "print(f\"The default configuration has an accuracy of {objective_default:.3f}. \" \n",
    "      f\"The best configuration found by DeepHyper has an accuracy {results['objective'].iloc[i_max]:.3f}, \" \n",
    "      f\"trained in {results['duration'].iloc[i_max]:.2f} secondes and \"\n",
    "      f\"finished after {results['elapsed_sec'].iloc[i_max]:.2f} secondes of search.\")\n",
    "\n",
    "\n",
    "\n",
    "best_config"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8349d84",
   "metadata": {},
   "source": [
    "## Restart from a checkpoint\n",
    "\n",
    "It can often be useful to continue the search from previous results. For example, if the allocation requested was not enough or if an unexpected crash happened. The `AMBS` searhc provides the `fit_surrogate(dataframe_of_results)` method for this use case. \n",
    "\n",
    "To simulate this we create a second evaluator `evaluator_2` and start a fresh AMBS search with strong explotation `kappa=0.001`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "3e99249c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created new evaluator with 1 worker and config: {'num_cpus': 1, 'num_cpus_per_task': 1, 'callbacks': [<deephyper.evaluator.callback.LoggerCallback object at 0x7f87479c8820>]}\n"
     ]
    }
   ],
   "source": [
    "evaluator_2 = get_evaluator(run)\n",
    "\n",
    "search_from_checkpoint = AMBS(problem, evaluator_2, kappa=0.001)\n",
    "\n",
    "# Initialize surrogate model of Bayesian optization (in AMBS)\n",
    "# With results of previous search\n",
    "search_from_checkpoint.fit_surrogate(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "9baeb24f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[00001] -- best objective: 0.7868852615356445 -- received objective: 0.7868852615356445\n",
      "[00002] -- best objective: 0.7868852615356445 -- received objective: 0.7868852615356445\n",
      "[00003] -- best objective: 0.8196721076965332 -- received objective: 0.8196721076965332\n",
      "[00004] -- best objective: 0.8196721076965332 -- received objective: 0.8032786846160889\n",
      "[00005] -- best objective: 0.8196721076965332 -- received objective: 0.7868852615356445\n",
      "[00006] -- best objective: 0.8196721076965332 -- received objective: 0.8032786846160889\n",
      "[00007] -- best objective: 0.8196721076965332 -- received objective: 0.8032786846160889\n",
      "[00008] -- best objective: 0.8524590134620667 -- received objective: 0.8524590134620667\n",
      "[00009] -- best objective: 0.8524590134620667 -- received objective: 0.7868852615356445\n",
      "[00010] -- best objective: 0.8524590134620667 -- received objective: 0.8032786846160889\n"
     ]
    }
   ],
   "source": [
    "results_from_checkpoint = search_from_checkpoint.search(max_evals=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "7f293587",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>activation</th>\n",
       "      <th>batch_size</th>\n",
       "      <th>dropout_rate</th>\n",
       "      <th>learning_rate</th>\n",
       "      <th>num_epochs</th>\n",
       "      <th>units</th>\n",
       "      <th>id</th>\n",
       "      <th>objective</th>\n",
       "      <th>elapsed_sec</th>\n",
       "      <th>duration</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>tanh</td>\n",
       "      <td>8</td>\n",
       "      <td>0.295913</td>\n",
       "      <td>0.001246</td>\n",
       "      <td>21</td>\n",
       "      <td>25</td>\n",
       "      <td>1</td>\n",
       "      <td>0.786885</td>\n",
       "      <td>7.634545</td>\n",
       "      <td>7.389596</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>softplus</td>\n",
       "      <td>51</td>\n",
       "      <td>0.543369</td>\n",
       "      <td>0.000456</td>\n",
       "      <td>35</td>\n",
       "      <td>59</td>\n",
       "      <td>2</td>\n",
       "      <td>0.786885</td>\n",
       "      <td>10.548635</td>\n",
       "      <td>2.736648</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>softplus</td>\n",
       "      <td>9</td>\n",
       "      <td>0.336213</td>\n",
       "      <td>0.000995</td>\n",
       "      <td>31</td>\n",
       "      <td>97</td>\n",
       "      <td>3</td>\n",
       "      <td>0.819672</td>\n",
       "      <td>15.254908</td>\n",
       "      <td>4.530637</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>gelu</td>\n",
       "      <td>10</td>\n",
       "      <td>0.502697</td>\n",
       "      <td>0.000744</td>\n",
       "      <td>54</td>\n",
       "      <td>14</td>\n",
       "      <td>4</td>\n",
       "      <td>0.803279</td>\n",
       "      <td>19.885343</td>\n",
       "      <td>4.451506</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>linear</td>\n",
       "      <td>36</td>\n",
       "      <td>0.001525</td>\n",
       "      <td>0.003873</td>\n",
       "      <td>19</td>\n",
       "      <td>20</td>\n",
       "      <td>5</td>\n",
       "      <td>0.786885</td>\n",
       "      <td>22.680793</td>\n",
       "      <td>2.609599</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>hard_sigmoid</td>\n",
       "      <td>16</td>\n",
       "      <td>0.015906</td>\n",
       "      <td>0.002015</td>\n",
       "      <td>80</td>\n",
       "      <td>94</td>\n",
       "      <td>6</td>\n",
       "      <td>0.803279</td>\n",
       "      <td>27.812362</td>\n",
       "      <td>4.844054</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>hard_sigmoid</td>\n",
       "      <td>11</td>\n",
       "      <td>0.147917</td>\n",
       "      <td>0.001193</td>\n",
       "      <td>47</td>\n",
       "      <td>99</td>\n",
       "      <td>7</td>\n",
       "      <td>0.803279</td>\n",
       "      <td>32.108787</td>\n",
       "      <td>4.118992</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>selu</td>\n",
       "      <td>19</td>\n",
       "      <td>0.378121</td>\n",
       "      <td>0.000221</td>\n",
       "      <td>20</td>\n",
       "      <td>91</td>\n",
       "      <td>8</td>\n",
       "      <td>0.852459</td>\n",
       "      <td>34.828211</td>\n",
       "      <td>2.540145</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>softplus</td>\n",
       "      <td>14</td>\n",
       "      <td>0.184656</td>\n",
       "      <td>0.007196</td>\n",
       "      <td>19</td>\n",
       "      <td>84</td>\n",
       "      <td>9</td>\n",
       "      <td>0.786885</td>\n",
       "      <td>37.828185</td>\n",
       "      <td>2.824502</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>selu</td>\n",
       "      <td>10</td>\n",
       "      <td>0.453426</td>\n",
       "      <td>0.000101</td>\n",
       "      <td>24</td>\n",
       "      <td>84</td>\n",
       "      <td>10</td>\n",
       "      <td>0.803279</td>\n",
       "      <td>40.995007</td>\n",
       "      <td>2.992048</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     activation  batch_size  dropout_rate  learning_rate  num_epochs  units  \\\n",
       "0          tanh           8      0.295913       0.001246          21     25   \n",
       "1      softplus          51      0.543369       0.000456          35     59   \n",
       "2      softplus           9      0.336213       0.000995          31     97   \n",
       "3          gelu          10      0.502697       0.000744          54     14   \n",
       "4        linear          36      0.001525       0.003873          19     20   \n",
       "5  hard_sigmoid          16      0.015906       0.002015          80     94   \n",
       "6  hard_sigmoid          11      0.147917       0.001193          47     99   \n",
       "7          selu          19      0.378121       0.000221          20     91   \n",
       "8      softplus          14      0.184656       0.007196          19     84   \n",
       "9          selu          10      0.453426       0.000101          24     84   \n",
       "\n",
       "   id  objective  elapsed_sec  duration  \n",
       "0   1   0.786885     7.634545  7.389596  \n",
       "1   2   0.786885    10.548635  2.736648  \n",
       "2   3   0.819672    15.254908  4.530637  \n",
       "3   4   0.803279    19.885343  4.451506  \n",
       "4   5   0.786885    22.680793  2.609599  \n",
       "5   6   0.803279    27.812362  4.844054  \n",
       "6   7   0.803279    32.108787  4.118992  \n",
       "7   8   0.852459    34.828211  2.540145  \n",
       "8   9   0.786885    37.828185  2.824502  \n",
       "9  10   0.803279    40.995007  2.992048  "
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_from_checkpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "8f28d724",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The default configuration has an accuracy of 0.820. The best configuration found by DeepHyper has an accuracy 0.852, trained in 2.54 secondes and finished after 34.83 secondes of search.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'activation': 'selu',\n",
       " 'batch_size': 19,\n",
       " 'dropout_rate': 0.3781208375459394,\n",
       " 'learning_rate': 0.0002212993363258,\n",
       " 'num_epochs': 20,\n",
       " 'units': 91,\n",
       " 'id': 8}"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "i_max = results_from_checkpoint.objective.argmax()\n",
    "best_config = results_from_checkpoint.iloc[i_max][:-3].to_dict()\n",
    "\n",
    "print(f\"The default configuration has an accuracy of {objective_default:.3f}. \" \n",
    "      f\"The best configuration found by DeepHyper has an accuracy {results_from_checkpoint['objective'].iloc[i_max]:.3f}, \" \n",
    "      f\"trained in {results_from_checkpoint['duration'].iloc[i_max]:.2f} secondes and \"\n",
    "      f\"finished after {results_from_checkpoint['elapsed_sec'].iloc[i_max]:.2f} secondes of search.\")\n",
    "\n",
    "\n",
    "\n",
    "best_config"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b535c9d",
   "metadata": {},
   "source": [
    "## Add conditionnal hyperparameters\n",
    "\n",
    "Now we want to add the possibility to search for a second fully-connected layer. We simply add two new lines:\n",
    "\n",
    "```python\n",
    "if config.get(\"dense_2\", False):\n",
    "    x = tf.keras.layers.Dense(config[\"dense_2:units\"], activation=config[\"dense_2:activation\"])(x)\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "8a62e9f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_with_condition(config: dict):\n",
    "    tf.autograph.set_verbosity(0)\n",
    "    \n",
    "    train_dataframe, val_dataframe = load_data()\n",
    "\n",
    "    train_ds = dataframe_to_dataset(train_dataframe)\n",
    "    val_ds = dataframe_to_dataset(val_dataframe)\n",
    "\n",
    "    train_ds = train_ds.batch(config[\"batch_size\"])\n",
    "    val_ds = val_ds.batch(config[\"batch_size\"])\n",
    "\n",
    "    # Categorical features encoded as integers\n",
    "    sex = tf.keras.Input(shape=(1,), name=\"sex\", dtype=\"int64\")\n",
    "    cp = tf.keras.Input(shape=(1,), name=\"cp\", dtype=\"int64\")\n",
    "    fbs = tf.keras.Input(shape=(1,), name=\"fbs\", dtype=\"int64\")\n",
    "    restecg = tf.keras.Input(shape=(1,), name=\"restecg\", dtype=\"int64\")\n",
    "    exang = tf.keras.Input(shape=(1,), name=\"exang\", dtype=\"int64\")\n",
    "    ca = tf.keras.Input(shape=(1,), name=\"ca\", dtype=\"int64\")\n",
    "\n",
    "    # Categorical feature encoded as string\n",
    "    thal = tf.keras.Input(shape=(1,), name=\"thal\", dtype=\"string\")\n",
    "\n",
    "    # Numerical features\n",
    "    age = tf.keras.Input(shape=(1,), name=\"age\")\n",
    "    trestbps = tf.keras.Input(shape=(1,), name=\"trestbps\")\n",
    "    chol = tf.keras.Input(shape=(1,), name=\"chol\")\n",
    "    thalach = tf.keras.Input(shape=(1,), name=\"thalach\")\n",
    "    oldpeak = tf.keras.Input(shape=(1,), name=\"oldpeak\")\n",
    "    slope = tf.keras.Input(shape=(1,), name=\"slope\")\n",
    "\n",
    "    all_inputs = [\n",
    "        sex,\n",
    "        cp,\n",
    "        fbs,\n",
    "        restecg,\n",
    "        exang,\n",
    "        ca,\n",
    "        thal,\n",
    "        age,\n",
    "        trestbps,\n",
    "        chol,\n",
    "        thalach,\n",
    "        oldpeak,\n",
    "        slope,\n",
    "    ]\n",
    "\n",
    "    # Integer categorical features\n",
    "    sex_encoded = encode_categorical_feature(sex, \"sex\", train_ds, False)\n",
    "    cp_encoded = encode_categorical_feature(cp, \"cp\", train_ds, False)\n",
    "    fbs_encoded = encode_categorical_feature(fbs, \"fbs\", train_ds, False)\n",
    "    restecg_encoded = encode_categorical_feature(restecg, \"restecg\", train_ds, False)\n",
    "    exang_encoded = encode_categorical_feature(exang, \"exang\", train_ds, False)\n",
    "    ca_encoded = encode_categorical_feature(ca, \"ca\", train_ds, False)\n",
    "\n",
    "    # String categorical features\n",
    "    thal_encoded = encode_categorical_feature(thal, \"thal\", train_ds, True)\n",
    "\n",
    "    # Numerical features\n",
    "    age_encoded = encode_numerical_feature(age, \"age\", train_ds)\n",
    "    trestbps_encoded = encode_numerical_feature(trestbps, \"trestbps\", train_ds)\n",
    "    chol_encoded = encode_numerical_feature(chol, \"chol\", train_ds)\n",
    "    thalach_encoded = encode_numerical_feature(thalach, \"thalach\", train_ds)\n",
    "    oldpeak_encoded = encode_numerical_feature(oldpeak, \"oldpeak\", train_ds)\n",
    "    slope_encoded = encode_numerical_feature(slope, \"slope\", train_ds)\n",
    "\n",
    "    all_features = tf.keras.layers.concatenate(\n",
    "        [\n",
    "            sex_encoded,\n",
    "            cp_encoded,\n",
    "            fbs_encoded,\n",
    "            restecg_encoded,\n",
    "            exang_encoded,\n",
    "            slope_encoded,\n",
    "            ca_encoded,\n",
    "            thal_encoded,\n",
    "            age_encoded,\n",
    "            trestbps_encoded,\n",
    "            chol_encoded,\n",
    "            thalach_encoded,\n",
    "            oldpeak_encoded,\n",
    "        ]\n",
    "    )\n",
    "    x = tf.keras.layers.Dense(config[\"units\"], activation=config[\"activation\"])(\n",
    "        all_features\n",
    "    )\n",
    "    if config.get(\"dense_2\", False):\n",
    "        x = tf.keras.layers.Dense(config[\"dense_2:units\"], activation=config[\"dense_2:activation\"])(x)\n",
    "    x = tf.keras.layers.Dropout(config[\"dropout_rate\"])(x)\n",
    "    output = tf.keras.layers.Dense(1, activation=\"sigmoid\")(x)\n",
    "    model = tf.keras.Model(all_inputs, output)\n",
    "\n",
    "    optimizer = tf.keras.optimizers.Adam(learning_rate=config[\"learning_rate\"])\n",
    "    model.compile(optimizer, \"binary_crossentropy\", metrics=[\"accuracy\"])\n",
    "\n",
    "    history = model.fit(\n",
    "        train_ds, epochs=config[\"num_epochs\"], validation_data=val_ds, verbose=0\n",
    "    )\n",
    "\n",
    "    return history.history[\"val_accuracy\"][-1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5df1c9fb",
   "metadata": {},
   "source": [
    "To defined conditionnal hyperparameters we use [ConfigSpace](https://automl.github.io/ConfigSpace/master/index.html). We define `dense_2:units` and `dense_2:activation` as active hyperparameters only when `dense_2 == True`. The `cs.EqualsCondition` help us do that. Then we call\n",
    "\n",
    "```python\n",
    "problem_with_condition.add_condition(condition)\n",
    "```\n",
    "\n",
    "to register each new condition to the `HpProblem`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "4cda0275",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Configuration space object:\n",
       "  Hyperparameters:\n",
       "    activation, Type: Categorical, Choices: {elu, gelu, hard_sigmoid, linear, relu, selu, sigmoid, softplus, softsign, swish, tanh}, Default: elu\n",
       "    batch_size, Type: UniformInteger, Range: [8, 256], Default: 45, on log-scale\n",
       "    dense_2, Type: Categorical, Choices: {True, False}, Default: True\n",
       "    dense_2:activation, Type: Categorical, Choices: {elu, gelu, hard_sigmoid, linear, relu, selu, sigmoid, softplus, softsign, swish, tanh}, Default: elu\n",
       "    dense_2:units, Type: UniformInteger, Range: [8, 128], Default: 68\n",
       "    dropout_rate, Type: UniformFloat, Range: [0.0, 0.6], Default: 0.3\n",
       "    learning_rate, Type: UniformFloat, Range: [1e-05, 0.01], Default: 0.0003162278, on log-scale\n",
       "    num_epochs, Type: UniformInteger, Range: [10, 100], Default: 55\n",
       "    units, Type: UniformInteger, Range: [8, 128], Default: 68\n",
       "  Conditions:\n",
       "    dense_2:activation | dense_2 == True\n",
       "    dense_2:units | dense_2 == True"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import ConfigSpace as cs\n",
    "\n",
    "# Define the same hyperparameters as before\n",
    "problem_with_condition = HpProblem()\n",
    "problem_with_condition.add_hyperparameter((8, 128), \"units\")\n",
    "problem_with_condition.add_hyperparameter(ACTIVATIONS, \"activation\")\n",
    "problem_with_condition.add_hyperparameter((0.0, 0.6), \"dropout_rate\")\n",
    "problem_with_condition.add_hyperparameter((10, 100), \"num_epochs\")\n",
    "problem_with_condition.add_hyperparameter((8, 256, \"log-uniform\"), \"batch_size\")\n",
    "problem_with_condition.add_hyperparameter((1e-5, 1e-2, \"log-uniform\"), \"learning_rate\")\n",
    "\n",
    "# Add a new hyperparameter \"dense_2 (bool)\" to decide if a second fully-connected layer should be created\n",
    "hp_dense_2 = problem_with_condition.add_hyperparameter([True, False], \"dense_2\")\n",
    "hp_dense_2_units = problem_with_condition.add_hyperparameter((8, 128), \"dense_2:units\")\n",
    "hp_dense_2_activation = problem_with_condition.add_hyperparameter(ACTIVATIONS, \"dense_2:activation\")\n",
    "\n",
    "problem_with_condition.add_condition(cs.EqualsCondition(hp_dense_2_units, hp_dense_2, True))\n",
    "problem_with_condition.add_condition(cs.EqualsCondition(hp_dense_2_activation, hp_dense_2, True))\n",
    "\n",
    "\n",
    "problem_with_condition"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc027194",
   "metadata": {},
   "source": [
    "We create a new evaluator `evaluator_3` and start a fresh AMBS search with this new problem `problem_with_condition`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "70192b13",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created new evaluator with 1 worker and config: {'num_cpus': 1, 'num_cpus_per_task': 1, 'callbacks': [<deephyper.evaluator.callback.LoggerCallback object at 0x7f8747a25910>]}\n"
     ]
    }
   ],
   "source": [
    "evaluator_3 = get_evaluator(run_with_condition)\n",
    "\n",
    "search_with_condition = AMBS(problem_with_condition, evaluator_3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "7705a8a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[00001] -- best objective: 0.8196721076965332 -- received objective: 0.8196721076965332\n",
      "[00002] -- best objective: 0.8196721076965332 -- received objective: 0.6557376980781555\n",
      "[00003] -- best objective: 0.8196721076965332 -- received objective: 0.7377049326896667\n",
      "[00004] -- best objective: 0.8196721076965332 -- received objective: 0.8196721076965332\n",
      "[00005] -- best objective: 0.8196721076965332 -- received objective: 0.8032786846160889\n",
      "[00006] -- best objective: 0.8524590134620667 -- received objective: 0.8524590134620667\n",
      "[00007] -- best objective: 0.8524590134620667 -- received objective: 0.8032786846160889\n",
      "[00008] -- best objective: 0.8524590134620667 -- received objective: 0.688524603843689\n",
      "[00009] -- best objective: 0.8524590134620667 -- received objective: 0.688524603843689\n",
      "[00010] -- best objective: 0.8524590134620667 -- received objective: 0.6229507923126221\n",
      "[00011] -- best objective: 0.8524590134620667 -- received objective: 0.8032786846160889\n",
      "[00012] -- best objective: 0.8524590134620667 -- received objective: 0.8524590134620667\n",
      "[00013] -- best objective: 0.8524590134620667 -- received objective: 0.8032786846160889\n",
      "[00014] -- best objective: 0.8524590134620667 -- received objective: 0.7868852615356445\n",
      "[00015] -- best objective: 0.8524590134620667 -- received objective: 0.7377049326896667\n",
      "[00016] -- best objective: 0.8524590134620667 -- received objective: 0.8032786846160889\n",
      "[00017] -- best objective: 0.8524590134620667 -- received objective: 0.7868852615356445\n",
      "[00018] -- best objective: 0.8524590134620667 -- received objective: 0.7704917788505554\n",
      "[00019] -- best objective: 0.8524590134620667 -- received objective: 0.8032786846160889\n",
      "[00020] -- best objective: 0.8524590134620667 -- received objective: 0.3442623019218445\n"
     ]
    }
   ],
   "source": [
    "results_with_condition = search_with_condition.search(max_evals=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "4764b947",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>activation</th>\n",
       "      <th>batch_size</th>\n",
       "      <th>dense_2</th>\n",
       "      <th>dropout_rate</th>\n",
       "      <th>learning_rate</th>\n",
       "      <th>num_epochs</th>\n",
       "      <th>units</th>\n",
       "      <th>dense_2:activation</th>\n",
       "      <th>dense_2:units</th>\n",
       "      <th>id</th>\n",
       "      <th>objective</th>\n",
       "      <th>elapsed_sec</th>\n",
       "      <th>duration</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>tanh</td>\n",
       "      <td>27</td>\n",
       "      <td>False</td>\n",
       "      <td>0.256561</td>\n",
       "      <td>0.000117</td>\n",
       "      <td>79</td>\n",
       "      <td>15</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>0.819672</td>\n",
       "      <td>7.361361</td>\n",
       "      <td>7.171424</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>softsign</td>\n",
       "      <td>188</td>\n",
       "      <td>False</td>\n",
       "      <td>0.494313</td>\n",
       "      <td>0.000016</td>\n",
       "      <td>87</td>\n",
       "      <td>99</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2</td>\n",
       "      <td>0.655738</td>\n",
       "      <td>11.200777</td>\n",
       "      <td>3.619191</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>hard_sigmoid</td>\n",
       "      <td>152</td>\n",
       "      <td>False</td>\n",
       "      <td>0.269453</td>\n",
       "      <td>0.000363</td>\n",
       "      <td>49</td>\n",
       "      <td>45</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3</td>\n",
       "      <td>0.737705</td>\n",
       "      <td>14.658631</td>\n",
       "      <td>3.234346</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>tanh</td>\n",
       "      <td>34</td>\n",
       "      <td>True</td>\n",
       "      <td>0.271216</td>\n",
       "      <td>0.000011</td>\n",
       "      <td>97</td>\n",
       "      <td>77</td>\n",
       "      <td>tanh</td>\n",
       "      <td>26.0</td>\n",
       "      <td>4</td>\n",
       "      <td>0.819672</td>\n",
       "      <td>19.757613</td>\n",
       "      <td>4.868647</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>softsign</td>\n",
       "      <td>10</td>\n",
       "      <td>True</td>\n",
       "      <td>0.273368</td>\n",
       "      <td>0.000174</td>\n",
       "      <td>55</td>\n",
       "      <td>63</td>\n",
       "      <td>sigmoid</td>\n",
       "      <td>87.0</td>\n",
       "      <td>5</td>\n",
       "      <td>0.803279</td>\n",
       "      <td>24.842931</td>\n",
       "      <td>4.855399</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>tanh</td>\n",
       "      <td>8</td>\n",
       "      <td>False</td>\n",
       "      <td>0.563932</td>\n",
       "      <td>0.000013</td>\n",
       "      <td>97</td>\n",
       "      <td>42</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6</td>\n",
       "      <td>0.852459</td>\n",
       "      <td>32.050291</td>\n",
       "      <td>6.985657</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>elu</td>\n",
       "      <td>8</td>\n",
       "      <td>True</td>\n",
       "      <td>0.390134</td>\n",
       "      <td>0.000014</td>\n",
       "      <td>42</td>\n",
       "      <td>89</td>\n",
       "      <td>elu</td>\n",
       "      <td>11.0</td>\n",
       "      <td>7</td>\n",
       "      <td>0.803279</td>\n",
       "      <td>37.850756</td>\n",
       "      <td>5.557407</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>relu</td>\n",
       "      <td>68</td>\n",
       "      <td>False</td>\n",
       "      <td>0.574432</td>\n",
       "      <td>0.000014</td>\n",
       "      <td>81</td>\n",
       "      <td>63</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>8</td>\n",
       "      <td>0.688525</td>\n",
       "      <td>42.979496</td>\n",
       "      <td>4.781515</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>softsign</td>\n",
       "      <td>15</td>\n",
       "      <td>False</td>\n",
       "      <td>0.463158</td>\n",
       "      <td>0.000011</td>\n",
       "      <td>87</td>\n",
       "      <td>11</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>9</td>\n",
       "      <td>0.688525</td>\n",
       "      <td>49.762694</td>\n",
       "      <td>6.417276</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>selu</td>\n",
       "      <td>224</td>\n",
       "      <td>True</td>\n",
       "      <td>0.127696</td>\n",
       "      <td>0.000023</td>\n",
       "      <td>60</td>\n",
       "      <td>82</td>\n",
       "      <td>selu</td>\n",
       "      <td>103.0</td>\n",
       "      <td>10</td>\n",
       "      <td>0.622951</td>\n",
       "      <td>53.507548</td>\n",
       "      <td>3.486371</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>tanh</td>\n",
       "      <td>18</td>\n",
       "      <td>False</td>\n",
       "      <td>0.543603</td>\n",
       "      <td>0.002916</td>\n",
       "      <td>63</td>\n",
       "      <td>100</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>11</td>\n",
       "      <td>0.803279</td>\n",
       "      <td>59.440492</td>\n",
       "      <td>5.568430</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>selu</td>\n",
       "      <td>10</td>\n",
       "      <td>False</td>\n",
       "      <td>0.187548</td>\n",
       "      <td>0.000020</td>\n",
       "      <td>89</td>\n",
       "      <td>54</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>12</td>\n",
       "      <td>0.852459</td>\n",
       "      <td>66.656329</td>\n",
       "      <td>6.771702</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>tanh</td>\n",
       "      <td>12</td>\n",
       "      <td>True</td>\n",
       "      <td>0.581329</td>\n",
       "      <td>0.000031</td>\n",
       "      <td>44</td>\n",
       "      <td>68</td>\n",
       "      <td>gelu</td>\n",
       "      <td>53.0</td>\n",
       "      <td>13</td>\n",
       "      <td>0.803279</td>\n",
       "      <td>71.125347</td>\n",
       "      <td>4.242962</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>elu</td>\n",
       "      <td>29</td>\n",
       "      <td>True</td>\n",
       "      <td>0.237516</td>\n",
       "      <td>0.000013</td>\n",
       "      <td>96</td>\n",
       "      <td>30</td>\n",
       "      <td>softplus</td>\n",
       "      <td>127.0</td>\n",
       "      <td>14</td>\n",
       "      <td>0.786885</td>\n",
       "      <td>76.928847</td>\n",
       "      <td>5.530758</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>selu</td>\n",
       "      <td>28</td>\n",
       "      <td>False</td>\n",
       "      <td>0.049217</td>\n",
       "      <td>0.000042</td>\n",
       "      <td>25</td>\n",
       "      <td>75</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>15</td>\n",
       "      <td>0.737705</td>\n",
       "      <td>80.756020</td>\n",
       "      <td>3.387590</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>selu</td>\n",
       "      <td>21</td>\n",
       "      <td>False</td>\n",
       "      <td>0.225955</td>\n",
       "      <td>0.000020</td>\n",
       "      <td>95</td>\n",
       "      <td>110</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>16</td>\n",
       "      <td>0.803279</td>\n",
       "      <td>86.354619</td>\n",
       "      <td>5.269145</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>softplus</td>\n",
       "      <td>10</td>\n",
       "      <td>True</td>\n",
       "      <td>0.174505</td>\n",
       "      <td>0.000046</td>\n",
       "      <td>78</td>\n",
       "      <td>34</td>\n",
       "      <td>hard_sigmoid</td>\n",
       "      <td>72.0</td>\n",
       "      <td>17</td>\n",
       "      <td>0.786885</td>\n",
       "      <td>93.094792</td>\n",
       "      <td>6.496757</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>hard_sigmoid</td>\n",
       "      <td>12</td>\n",
       "      <td>True</td>\n",
       "      <td>0.221041</td>\n",
       "      <td>0.000014</td>\n",
       "      <td>77</td>\n",
       "      <td>128</td>\n",
       "      <td>relu</td>\n",
       "      <td>63.0</td>\n",
       "      <td>18</td>\n",
       "      <td>0.770492</td>\n",
       "      <td>99.075099</td>\n",
       "      <td>5.743155</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>selu</td>\n",
       "      <td>8</td>\n",
       "      <td>False</td>\n",
       "      <td>0.019556</td>\n",
       "      <td>0.000030</td>\n",
       "      <td>95</td>\n",
       "      <td>34</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>19</td>\n",
       "      <td>0.803279</td>\n",
       "      <td>107.442019</td>\n",
       "      <td>8.098483</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>softplus</td>\n",
       "      <td>10</td>\n",
       "      <td>False</td>\n",
       "      <td>0.364774</td>\n",
       "      <td>0.000011</td>\n",
       "      <td>82</td>\n",
       "      <td>54</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>20</td>\n",
       "      <td>0.344262</td>\n",
       "      <td>113.803357</td>\n",
       "      <td>6.113380</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      activation  batch_size  dense_2  dropout_rate  learning_rate  \\\n",
       "0           tanh          27    False      0.256561       0.000117   \n",
       "1       softsign         188    False      0.494313       0.000016   \n",
       "2   hard_sigmoid         152    False      0.269453       0.000363   \n",
       "3           tanh          34     True      0.271216       0.000011   \n",
       "4       softsign          10     True      0.273368       0.000174   \n",
       "5           tanh           8    False      0.563932       0.000013   \n",
       "6            elu           8     True      0.390134       0.000014   \n",
       "7           relu          68    False      0.574432       0.000014   \n",
       "8       softsign          15    False      0.463158       0.000011   \n",
       "9           selu         224     True      0.127696       0.000023   \n",
       "10          tanh          18    False      0.543603       0.002916   \n",
       "11          selu          10    False      0.187548       0.000020   \n",
       "12          tanh          12     True      0.581329       0.000031   \n",
       "13           elu          29     True      0.237516       0.000013   \n",
       "14          selu          28    False      0.049217       0.000042   \n",
       "15          selu          21    False      0.225955       0.000020   \n",
       "16      softplus          10     True      0.174505       0.000046   \n",
       "17  hard_sigmoid          12     True      0.221041       0.000014   \n",
       "18          selu           8    False      0.019556       0.000030   \n",
       "19      softplus          10    False      0.364774       0.000011   \n",
       "\n",
       "    num_epochs  units dense_2:activation  dense_2:units  id  objective  \\\n",
       "0           79     15                NaN            NaN   1   0.819672   \n",
       "1           87     99                NaN            NaN   2   0.655738   \n",
       "2           49     45                NaN            NaN   3   0.737705   \n",
       "3           97     77               tanh           26.0   4   0.819672   \n",
       "4           55     63            sigmoid           87.0   5   0.803279   \n",
       "5           97     42                NaN            NaN   6   0.852459   \n",
       "6           42     89                elu           11.0   7   0.803279   \n",
       "7           81     63                NaN            NaN   8   0.688525   \n",
       "8           87     11                NaN            NaN   9   0.688525   \n",
       "9           60     82               selu          103.0  10   0.622951   \n",
       "10          63    100                NaN            NaN  11   0.803279   \n",
       "11          89     54                NaN            NaN  12   0.852459   \n",
       "12          44     68               gelu           53.0  13   0.803279   \n",
       "13          96     30           softplus          127.0  14   0.786885   \n",
       "14          25     75                NaN            NaN  15   0.737705   \n",
       "15          95    110                NaN            NaN  16   0.803279   \n",
       "16          78     34       hard_sigmoid           72.0  17   0.786885   \n",
       "17          77    128               relu           63.0  18   0.770492   \n",
       "18          95     34                NaN            NaN  19   0.803279   \n",
       "19          82     54                NaN            NaN  20   0.344262   \n",
       "\n",
       "    elapsed_sec  duration  \n",
       "0      7.361361  7.171424  \n",
       "1     11.200777  3.619191  \n",
       "2     14.658631  3.234346  \n",
       "3     19.757613  4.868647  \n",
       "4     24.842931  4.855399  \n",
       "5     32.050291  6.985657  \n",
       "6     37.850756  5.557407  \n",
       "7     42.979496  4.781515  \n",
       "8     49.762694  6.417276  \n",
       "9     53.507548  3.486371  \n",
       "10    59.440492  5.568430  \n",
       "11    66.656329  6.771702  \n",
       "12    71.125347  4.242962  \n",
       "13    76.928847  5.530758  \n",
       "14    80.756020  3.387590  \n",
       "15    86.354619  5.269145  \n",
       "16    93.094792  6.496757  \n",
       "17    99.075099  5.743155  \n",
       "18   107.442019  8.098483  \n",
       "19   113.803357  6.113380  "
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_with_condition"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63ca8219",
   "metadata": {},
   "source": [
    "Finally, let us print out the best configuration found from this conditionned search space."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "34f26be4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The default configuration has an accuracy of 0.820. The best configuration found by DeepHyper has an accuracy 0.852, trained in 6.99 secondes and finished after 32.05 secondes of search.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'activation': 'tanh',\n",
       " 'batch_size': 8,\n",
       " 'dense_2': False,\n",
       " 'dropout_rate': 0.5639315153285624,\n",
       " 'learning_rate': 1.3286479422843164e-05,\n",
       " 'num_epochs': 97,\n",
       " 'units': 42,\n",
       " 'dense_2:activation': nan,\n",
       " 'dense_2:units': nan,\n",
       " 'id': 6}"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "i_max = results_with_condition.objective.argmax()\n",
    "best_config = results_with_condition.iloc[i_max][:-3].to_dict()\n",
    "\n",
    "print(f\"The default configuration has an accuracy of {objective_default:.3f}. \" \n",
    "      f\"The best configuration found by DeepHyper has an accuracy {results_with_condition['objective'].iloc[i_max]:.3f}, \" \n",
    "      f\"trained in {results_with_condition['duration'].iloc[i_max]:.2f} secondes and \"\n",
    "      f\"finished after {results_with_condition['elapsed_sec'].iloc[i_max]:.2f} secondes of search.\")\n",
    "\n",
    "\n",
    "\n",
    "best_config"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
